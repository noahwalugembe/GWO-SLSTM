Figure: training_history_comprehensive
==================================================
Description: Comprehensive training history showing evolution of MSE, RMSE, MAPE, and PBIAS across epochs for GWO-SLSTM
==================================================

Values used in the figure:
------------------------------
Training_MSE_values: [17617.246, 12472.743, 6618.888, 1581.8239, 219.25174, 158.41862, 168.04953, 305.95636, 174.10168, 188.80243] ... (showing first 10 of 28 values)
Validation_MSE_values: [722493.8, 506724.44, 255672.05, 47294.79, 4026.2612, 5523.1333, 4177.1714, 3714.4563, 3971.5134, 3665.7307] ... (showing first 10 of 28 values)
Training_RMSE_values: [132.7299743605415, 111.68143607629023, 81.35654972768788, 39.77214920693955, 14.807151633651664, 12.586446078140154, 12.963391918371398, 17.491608269775575, 13.194759739014291, 13.740539625473913] ... (showing first 10 of 28 values)
Validation_RMSE_values: [849.996360286325, 711.8457961525095, 505.6402346283373, 217.4736514212699, 63.452826812276456, 74.3177858980019, 64.6310404273268, 60.946339503108184, 63.019944682095485, 60.54527820475041] ... (showing first 10 of 28 values)
Training_MAPE_values: [32.06731081008911, 26.735132932662964, 19.28495168685913, 8.709405362606049, 2.6717282831668854, 2.0636485889554024, 2.3643478751182556, 3.6404624581336975, 2.50001884996891, 2.3413337767124176] ... (showing first 10 of 28 values)
Validation_MAPE_values: [54.316240549087524, 45.66850960254669, 32.71885812282562, 14.472836256027222, 2.6424435898661613, 3.1333211809396744, 2.6586977764964104, 2.7192270383238792, 2.646680362522602, 2.567364275455475] ... (showing first 10 of 28 values)
Training_PBIAS_values: [-2.1924126893281937, -1.2731428258121014, -0.4588397219777107, 1.2932575307786465, 1.855684071779251, -0.20782786887139082, -0.521061709150672, 3.003104589879513, -0.8068391121923923, 1.2720060534775257] ... (showing first 10 of 28 values)
Validation_PBIAS_values: [57.867878675460815, 48.57451021671295, 34.66458320617676, 15.018154680728912, -0.9552783332765102, -2.7437886223196983, -1.6593845561146736, -0.4498295020312071, -1.5821617096662521, -0.9145894087851048] ... (showing first 10 of 28 values)
Final_training_MSE: 160.50119018554688
Final_validation_MSE: 3599.47314453125
Number_of_epochs: 28
